{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf11d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thermal Runaway Detection Pipeline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import joblib\n",
    "\n",
    "# TODO: Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f190cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: X.shape=(0,), y.shape=(0,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 107\u001b[0m\n\u001b[1;32m    105\u001b[0m X, y \u001b[38;5;241m=\u001b[39m load_all_data(DATA_DIR, WINDOW_SIZE, STRIDE)\n\u001b[1;32m    106\u001b[0m FEATURES \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 107\u001b[0m X_tr_s, X_te_s, y_tr, y_te \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_ml_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m X_tr_dl, X_te_dl, y_tr_dl, y_te_dl \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m    110\u001b[0m summary, confusion_matrices, roc_curves \u001b[38;5;241m=\u001b[39m [], {}, {}\n",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m, in \u001b[0;36mprepare_ml_data\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_ml_data\u001b[39m(X, y):\n\u001b[0;32m---> 31\u001b[0m     n, T, F \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     32\u001b[0m     X_flat \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(n, T \u001b[38;5;241m*\u001b[39m F)\n\u001b[1;32m     33\u001b[0m     X_tr, X_te, y_tr, y_te \u001b[38;5;241m=\u001b[39m train_test_split(X_flat, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "#Thermal Runaway Detection Pipeline\n",
    "\n",
    "#Configurations\n",
    "DATA_DIR = \"./data\"\n",
    "RESULTS_DIR = \"./results\"\n",
    "WINDOW_SIZE = 100\n",
    "STRIDE = 1\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "#Loading Data\n",
    "def load_all_data(data_dir, window_size, stride):\n",
    "    X_list, y_list = [], []\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        label = 0 if 'healthy' in root.lower() else 1\n",
    "        for fname in files:\n",
    "            if fname.endswith(\".csv\"):\n",
    "                df = pd.read_csv(os.path.join(root, fname))\n",
    "                if df.isnull().values.any() or len(df) < window_size:\n",
    "                    continue\n",
    "                arr = df.values.astype(np.float32)\n",
    "                for i in range(0, len(arr) - window_size + 1, stride):\n",
    "                    X_list.append(arr[i:i + window_size])\n",
    "                    y_list.append(label)\n",
    "    X = np.array(X_list)\n",
    "    y = np.array(y_list)\n",
    "    print(f\"Loaded: X.shape={X.shape}, y.shape={y.shape}\")\n",
    "    return X, y\n",
    "\n",
    "#Scaling\n",
    "def prepare_ml_data(X, y):\n",
    "    n, T, F = X.shape\n",
    "    X_flat = X.reshape(n, T * F)\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_flat, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    scaler = RobustScaler()\n",
    "    return scaler.fit_transform(X_tr), scaler.transform(X_te), y_tr, y_te\n",
    "\n",
    "#Wrapper for Keras Classifier\n",
    "\n",
    "#Deep Learning Models\n",
    "def build_lstm(units=64, learning_rate=0.001, features=2):\n",
    "    model = Sequential([\n",
    "        LSTM(units, input_shape=(WINDOW_SIZE, features)),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn(filters=32, kernel_size=3, learning_rate=0.001, features=2):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters, kernel_size, activation='relu', input_shape=(WINDOW_SIZE, features)),\n",
    "        MaxPooling1D(2),\n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#Plotting\n",
    "def save_all_confusion_matrices(conf_mats):\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(18, 15))\n",
    "    axs = axs.flatten()\n",
    "    for ax, (name, cm) in zip(axs, conf_mats.items()):\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=[\"Healthy\", \"Runaway\"],\n",
    "                    yticklabels=[\"Healthy\", \"Runaway\"], ax=ax)\n",
    "        ax.set_title(f\"Confusion: {name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, \"all_confusion_matrices.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def save_all_roc_curves(roc_data):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    for name, (y_true, y_prob) in sorted(roc_data.items()):\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "        auc_val = auc(fpr, tpr)\n",
    "        ax.plot(fpr, tpr, label=f\"{name} (AUC={auc_val:.3f})\")\n",
    "    ax.plot([0, 1], [0, 1], '--', color='gray')\n",
    "    ax.set_title(\"ROC Curves\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, \"all_roc_curves_sorted.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def save_auc_comparison(train_aucs, test_aucs):\n",
    "    labels = list(train_aucs.keys())\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(x - width/2, [train_aucs[l] for l in labels], width, label=\"Train AUC\")\n",
    "    plt.bar(x + width/2, [test_aucs[l] for l in labels], width, label=\"Test AUC\")\n",
    "    plt.xticks(x, labels, rotation=45)\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.title(\"Train vs Test AUC Comparison\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, \"train_vs_test_auc.png\"))\n",
    "    plt.close()\n",
    "\n",
    "#Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    X, y = load_all_data(DATA_DIR, WINDOW_SIZE, STRIDE)\n",
    "    _, _, FEATURES = X.shape\n",
    "    X_tr_s, X_te_s, y_tr, y_te = prepare_ml_data(X, y)\n",
    "    X_tr_dl, X_te_dl, y_tr_dl, y_te_dl = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    summary, confusion_matrices, roc_curves = [], {}, {}\n",
    "    train_auc, test_auc = {}, {}\n",
    "    best_params_all = {}\n",
    "\n",
    "    #Classical Models with GridSearchCV\n",
    "    classical_defs = {\n",
    "        \"RandomForest\": (RandomForestClassifier(), {\"n_estimators\": [100, 200]}),\n",
    "        \"SVM\": (SVC(probability=True), {\"C\": [0.1, 1, 10], \"gamma\": [\"scale\"], \"kernel\": [\"rbf\"]}),\n",
    "        \"GB\": (GradientBoostingClassifier(), {\"n_estimators\": [100, 200], \"learning_rate\": [0.05, 0.1]})\n",
    "    }\n",
    "\n",
    "    for name, (model, grid) in classical_defs.items():\n",
    "        gs = GridSearchCV(model, grid, cv=3, scoring=\"roc_auc\", n_jobs=-1)\n",
    "        gs.fit(X_tr_s, y_tr)\n",
    "        best = gs.best_estimator_\n",
    "        print(f\"🔍 Best {name} params:\", gs.best_params_)\n",
    "        best_params_all[name] = gs.best_params_\n",
    "\n",
    "        y_pred = best.predict(X_te_s)\n",
    "        y_prob = best.predict_proba(X_te_s)[:,1]\n",
    "        cm = confusion_matrix(y_te, y_pred)\n",
    "        confusion_matrices[name] = cm\n",
    "        roc_curves[name] = (y_te, y_prob)\n",
    "        train_auc[name] = roc_auc_score(y_tr, best.predict_proba(X_tr_s)[:,1])\n",
    "        test_auc[name] = roc_auc_score(y_te, y_prob)\n",
    "\n",
    "        df = pd.DataFrame(classification_report(y_te, y_pred, output_dict=True)).transpose(); df['model'] = name\n",
    "        summary.append(df)\n",
    "\n",
    "    #Deep Learning Models with GridSearchCV\n",
    "    deep_defs = {\n",
    "        \"LSTM\": (build_lstm, {\n",
    "            \"units\": [32, 64],\n",
    "            \"learning_rate\": [0.001, 0.0005],\n",
    "            \"epochs\": [10],\n",
    "            \"batch_size\": [32]\n",
    "        }),\n",
    "        \"CNN\": (build_cnn, {\n",
    "            \"filters\": [16, 32],\n",
    "            \"kernel_size\": [3],\n",
    "            \"learning_rate\": [0.001],\n",
    "            \"epochs\": [10],\n",
    "            \"batch_size\": [32]\n",
    "        })\n",
    "    }\n",
    "\n",
    "    for name, (builder, grid) in deep_defs.items():\n",
    "        keras_clf = MyKerasClassifier(build_fn=builder)\n",
    "        gs = GridSearchCV(keras_clf, grid, cv=3, scoring=\"roc_auc\", n_jobs=1)\n",
    "        gs.fit(X_tr_dl, y_tr_dl)\n",
    "        print(f\"🔍 Best {name} params:\", gs.best_params_)\n",
    "        best_params_all[name] = gs.best_params_\n",
    "        best_dl = gs.best_estimator_\n",
    "\n",
    "        y_pred = best_dl.predict(X_te_dl)\n",
    "        y_prob = best_dl.predict_proba(X_te_dl)\n",
    "        confusion_matrices[name] = confusion_matrix(y_te_dl, y_pred)\n",
    "        roc_curves[name] = (y_te_dl, y_prob)\n",
    "        train_auc[name] = roc_auc_score(y_tr_dl, best_dl.predict_proba(X_tr_dl))\n",
    "        test_auc[name] = roc_auc_score(y_te_dl, y_prob)\n",
    "\n",
    "        df = pd.DataFrame(classification_report(y_te_dl, y_pred, output_dict=True)).transpose(); df['model'] = name\n",
    "        summary.append(df)\n",
    "\n",
    "    #Ensemble Models\n",
    "    voting = VotingClassifier(estimators=[(k, v) for k, (v, _) in classical_defs.items()], voting='soft')\n",
    "    voting.fit(X_tr_s, y_tr)\n",
    "    y_prob = voting.predict_proba(X_te_s)[:,1]\n",
    "    y_pred = voting.predict(X_te_s)\n",
    "    confusion_matrices[\"Voting\"] = confusion_matrix(y_te, y_pred)\n",
    "    roc_curves[\"Voting\"] = (y_te, y_prob)\n",
    "    train_auc[\"Voting\"] = roc_auc_score(y_tr, voting.predict_proba(X_tr_s)[:,1])\n",
    "    test_auc[\"Voting\"] = roc_auc_score(y_te, y_prob)\n",
    "    df = pd.DataFrame(classification_report(y_te, y_pred, output_dict=True)).transpose(); df['model'] = \"Voting\"\n",
    "    summary.append(df)\n",
    "\n",
    "    stacking = StackingClassifier(estimators=[(k, v) for k, (v, _) in classical_defs.items()],\n",
    "                                   final_estimator=LogisticRegression())\n",
    "    stacking.fit(X_tr_s, y_tr)\n",
    "    y_prob = stacking.predict_proba(X_te_s)[:,1]\n",
    "    y_pred = stacking.predict(X_te_s)\n",
    "    confusion_matrices[\"Stacking\"] = confusion_matrix(y_te, y_pred)\n",
    "    roc_curves[\"Stacking\"] = (y_te, y_prob)\n",
    "    train_auc[\"Stacking\"] = roc_auc_score(y_tr, stacking.predict_proba(X_tr_s)[:,1])\n",
    "    test_auc[\"Stacking\"] = roc_auc_score(y_te, y_prob)\n",
    "    df = pd.DataFrame(classification_report(y_te, y_pred, output_dict=True)).transpose(); df['model'] = \"Stacking\"\n",
    "    summary.append(df)\n",
    "\n",
    "    #Save metrics and figures\n",
    "    pd.concat(summary).to_csv(os.path.join(RESULTS_DIR, \"summary_metrics.csv\"), index=False)\n",
    "    save_all_confusion_matrices(confusion_matrices)\n",
    "    save_all_roc_curves(roc_curves)\n",
    "    save_auc_comparison(train_auc, test_auc)\n",
    "    print(\"\\n✅ Finished! All metrics and figures saved to:\", RESULTS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f438a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#Plotting Confusion Matrices\n",
    "fig, axs = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axs = axs.flatten()\n",
    "for ax, (name, cm) in zip(axs, confusion_matrices.items()):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"Healthy\", \"Runaway\"],\n",
    "                yticklabels=[\"Healthy\", \"Runaway\"], ax=ax)\n",
    "    ax.set_title(f\"Confusion: {name}\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#ROC Curves\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sorted_roc = sorted(roc_curves.items(), key=lambda x: auc(*roc_curve(x[1][0], x[1][1])[:2]), reverse=True)\n",
    "for name, (y_true, y_prob) in sorted_roc:\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, label=f\"{name} (AUC={auc_val:.3f})\")\n",
    "ax.plot([0, 1], [0, 1], '--', color='gray')\n",
    "ax.set_title(\"ROC Curves (Sorted by AUC)\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Train vs Test AUC Comparison\n",
    "labels = list(train_auc.keys())\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(x - width/2, [train_auc[k] for k in labels], width, label=\"Train AUC\")\n",
    "plt.bar(x + width/2, [test_auc[k] for k in labels], width, label=\"Test AUC\")\n",
    "plt.xticks(x, labels, rotation=45)\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"Train vs Test AUC Comparison\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-fix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
